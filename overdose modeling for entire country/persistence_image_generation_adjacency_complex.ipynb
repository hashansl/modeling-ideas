{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compute adjacency complex to track persistence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import geopandas as gpd\n",
    "import pickle as pickle\n",
    "from pylab import *\n",
    "import os    \n",
    "import numpy as np\n",
    "\n",
    "import warnings\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "import itertools\n",
    "from itertools import combinations\n",
    "from scipy import spatial\n",
    "import pickle as pickle\n",
    "import gudhi\n",
    "from pylab import *\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import io\n",
    "from tqdm import tqdm\n",
    "from PIL import Image, ImageDraw, ImageChops, ImageFont\n",
    "import shapely.geometry as geom\n",
    "from shapely.ops import unary_union\n",
    "\n",
    "import invr\n",
    "\n",
    "# Ignore FutureWarnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "import matplotlib as mpl\n",
    "mpl.rcParams.update(mpl.rcParamsDefault)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the list of folders in a location\n",
    "def get_folders(location):\n",
    "    return [name for name in os.listdir(location) if os.path.isdir(os.path.join(location, name))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "states = get_folders('/Users/h6x/ORNL/git/modeling-ideas/overdose modeling for entire country/data/processed data/svi with hepvu/2018/SVI2018 census tracts with death rate HepVu-5 classes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of states: 50\n",
      "['VT', 'VA', 'SD', 'SC', 'UT', 'GA', 'MS', 'MT', 'MO', 'MA', 'AK', 'KY', 'AL', 'NH', 'MN', 'MI', 'OK', 'IN', 'CO', 'CA', 'IA', 'CT', 'FL', 'WV', 'RI', 'WY', 'TX', 'PA', 'NC', 'ND', 'NM', 'NJ', 'ME', 'AR', 'NV', 'MD', 'KS', 'NE', 'HI', 'DE', 'AZ', 'NY', 'ID', 'OH', 'OR', 'IL', 'LA', 'WI', 'WA', 'TN']\n"
     ]
    }
   ],
   "source": [
    "print('Number of states:', len(states))\n",
    "print(states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done creating folders for each state\n"
     ]
    }
   ],
   "source": [
    "for state in states:\n",
    "    # create a folder for each state if it does not exist\n",
    "    os.makedirs(f\"/Users/h6x/ORNL/git/modeling-ideas/overdose modeling for entire country/data/processed data/selected coordinates for each state - percentiles(below 90th)- all variables/{state}\", exist_ok=True)\n",
    "print('Done creating folders for each state')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_variables = ['EP_POV','EP_UNEMP','EP_PCI','EP_NOHSDP','EP_UNINSUR','EP_AGE65','EP_AGE17','EP_DISABL','EP_SNGPNT','EP_LIMENG','EP_MINRTY','EP_MUNIT','EP_MOBILE','EP_CROWD','EP_NOVEH','EP_GROUPQ','NOD_Rate']\n",
    "selected_variables_without_y = ['EP_POV','EP_UNEMP','EP_PCI','EP_NOHSDP','EP_UNINSUR','EP_AGE65','EP_AGE17','EP_DISABL','EP_SNGPNT','EP_LIMENG','EP_MINRTY','EP_MUNIT','EP_MOBILE','EP_CROWD','EP_NOVEH','EP_GROUPQ']\n",
    "\n",
    "# selected_variables_for_state_with_geo = ['FIPS','EP_DISABL', 'EP_NOHSDP', 'EP_PCI', 'EP_MOBILE', 'EP_POV','NOD_Rate','geometry']\n",
    "# selected_variables_for_state = ['EP_DISABL', 'EP_NOHSDP', 'EP_PCI', 'EP_MOBILE', 'EP_POV']\n",
    "# selected_variables_tn_with_od = ['EP_DISABL', 'EP_NOHSDP', 'EP_PCI', 'EP_MOBILE', 'EP_POV','NOD_Rate']\n",
    "\n",
    "selected_variables_for_state_with_geo = ['FIPS','EP_POV','EP_UNEMP','EP_PCI','EP_NOHSDP','EP_UNINSUR','EP_AGE65','EP_AGE17','EP_DISABL','EP_SNGPNT','EP_LIMENG','EP_MINRTY','EP_MUNIT','EP_MOBILE','EP_CROWD','EP_NOVEH','EP_GROUPQ','NOD_Rate','geometry']\n",
    "selected_variables_for_state = ['EP_POV','EP_UNEMP','EP_PCI','EP_NOHSDP','EP_UNINSUR','EP_AGE65','EP_AGE17','EP_DISABL','EP_SNGPNT','EP_LIMENG','EP_MINRTY','EP_MUNIT','EP_MOBILE','EP_CROWD','EP_NOVEH','EP_GROUPQ']\n",
    "selected_variables_tn_with_od = ['EP_POV','EP_UNEMP','EP_PCI','EP_NOHSDP','EP_UNINSUR','EP_AGE65','EP_AGE17','EP_DISABL','EP_SNGPNT','EP_LIMENG','EP_MINRTY','EP_MUNIT','EP_MOBILE','EP_CROWD','EP_NOVEH','EP_GROUPQ','NOD_Rate']\n",
    "\n",
    "selected_variables_with_censusinfo = ['FIPS','STCNTY','EP_POV','EP_UNEMP','EP_PCI','EP_NOHSDP','EP_UNINSUR','EP_AGE65','EP_AGE17','EP_DISABL','EP_SNGPNT','EP_LIMENG','EP_MINRTY','EP_MUNIT','EP_MOBILE','EP_CROWD','EP_NOVEH','EP_GROUPQ','NOD_Rate','geometry']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def generate_adjacent_counties(dataframe,filtration_threshold,variable_name):\n",
    "def generate_adjacent_counties(dataframe,variable_name):\n",
    "\n",
    "\n",
    "    filtered_df = dataframe\n",
    "    # filtered_df = dataframe[dataframe[variable_name] < filtration_threshold]\n",
    "\n",
    "    # Perform a spatial join to find adjacent precincts\n",
    "    adjacent_counties = gpd.sjoin(filtered_df, filtered_df, predicate='intersects', how='left')\n",
    "\n",
    "    # Filter the results to include only the adjacent states\n",
    "    adjacent_counties = adjacent_counties.query('sortedID_left != sortedID_right')\n",
    "\n",
    "    # Group the resulting dataframe by the original precinct Name and create a list of adjacent precinct Name\n",
    "    adjacent_counties = adjacent_counties.groupby('sortedID_left')['sortedID_right'].apply(list).reset_index()\n",
    "\n",
    "    adjacent_counties.rename(columns={'sortedID_left': 'county', 'sortedID_right': 'adjacent'}, inplace=True)\n",
    "\n",
    "    adjacencies_list = adjacent_counties['adjacent'].tolist()\n",
    "    county_list = adjacent_counties['county'].tolist()\n",
    "\n",
    "    merged_df = pd.merge(adjacent_counties, dataframe, left_on='county',right_on='sortedID', how='left')\n",
    "    merged_df = gpd.GeoDataFrame(merged_df, geometry='geometry')\n",
    "\n",
    "    return adjacencies_list,merged_df,county_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def form_simplicial_complex(adjacent_county_list,county_list):\n",
    "    max_dimension = 3\n",
    "\n",
    "    V = []\n",
    "    V = invr.incremental_vr(V, adjacent_county_list, max_dimension,county_list)\n",
    "\n",
    "    return V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_simplicial_complex(dataframe,V):\n",
    "\n",
    "    #city centroids\n",
    "    city_coordinates = {city.sortedID: np.array((city.geometry.centroid.x, city.geometry.centroid.y)) for _, city in dataframe.iterrows()}\n",
    "\n",
    "    # Create a figure and axis\n",
    "    fig, ax = plt.subplots(figsize=(8, 8))\n",
    "    ax.set_axis_off() \n",
    "\n",
    "    # Plot the \"wyoming_svi\" DataFrame\n",
    "    dataframe.plot(ax=ax, edgecolor='black', linewidth=0.3, color=\"white\")\n",
    "\n",
    "    # Plot the centroid of the large square with values\n",
    "    # for i, row in dataframe.iterrows():\n",
    "    #     centroid = row['geometry'].centroid\n",
    "    #     # text_to_display = f\"FIPS: {row['FIPS']}\\nFilteration: {row['EP_SNGPNT']}\"\n",
    "    #     plt.text(centroid.x, centroid.y, str(row['FIPS']), fontsize=8, ha='center', color=\"black\")\n",
    "    #     # plt.text(centroid.x, centroid.y, text_to_display, fontsize=10, ha='center', color=\"black\")\n",
    "\n",
    "    for edge_or_traingle in V:\n",
    "\n",
    "        \n",
    "        if len(edge_or_traingle) == 2:\n",
    "            # Plot an edge\n",
    "            ax.plot(*zip(*[city_coordinates[vertex] for vertex in edge_or_traingle]), color='red', linewidth=1)\n",
    "            # img = fig2img(fig)\n",
    "            # list_gif.append(img)\n",
    "        elif len(edge_or_traingle) == 3:\n",
    "            # Plot a triangle\n",
    "            ax.add_patch(plt.Polygon([city_coordinates[vertex] for vertex in edge_or_traingle], color='green', alpha=0.2))\n",
    "            # img = fig2img(fig)\n",
    "            # list_gif.append(img)\n",
    "    # plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: VT\n",
      "Number of counties: 14\n",
      "Processing: 50001\n",
      "Number of rows: 10\n",
      "Processing: EP_GROUPQ\n",
      "Processing: EP_GROUPQ\n",
      "Processing: EP_GROUPQ\n",
      "Processing: EP_GROUPQ\n",
      "Processing: EP_GROUPQ\n",
      "Processing: EP_GROUPQ\n",
      "Processing: EP_GROUPQ\n",
      "Processing: EP_GROUPQ\n",
      "Processing: EP_GROUPQ\n",
      "Processing: EP_GROUPQ\n",
      "Processing: EP_GROUPQ\n",
      "Processing: EP_GROUPQ\n",
      "Processing: EP_GROUPQ\n",
      "Processing: EP_GROUPQ\n",
      "Processing: EP_GROUPQ\n",
      "Processing: EP_GROUPQ\n",
      "All states processed.\n"
     ]
    }
   ],
   "source": [
    "for state in states:\n",
    "\n",
    "    print('Processing:', state)\n",
    "\n",
    "    # Initialize dictionaries to store the percentiles\n",
    "    \n",
    "\n",
    "\n",
    "    svi_od = gpd.read_file(f'/Users/h6x/ORNL/git/modeling-ideas/overdose modeling for entire country/data/processed data/svi with hepvu/2018/SVI2018 census tracts with death rate HepVu-5 classes/{state}/{state}.shp')\n",
    "    \n",
    "    # Drop -999 in selected_variables_for_state\n",
    "    for variable in selected_variables_for_state:\n",
    "        svi_od = svi_od[svi_od[variable] != -999]\n",
    "\n",
    "    \n",
    "\n",
    "    svi_od_filtered_state = svi_od[selected_variables_with_censusinfo]\n",
    "\n",
    "    #reset index\n",
    "    svi_od_filtered_state = svi_od_filtered_state.reset_index(drop=True)\n",
    "\n",
    "    # get the uniques counties\n",
    "    unique_county_stcnty = svi_od_filtered_state['STCNTY'].unique()\n",
    "\n",
    "    print('Number of counties:', len(unique_county_stcnty))\n",
    "\n",
    "\n",
    "    # percentiles_50 = {}\n",
    "    # percentiles_75 = {}\n",
    "    # percentiles_90 = {}\n",
    "\n",
    "    for county_stcnty in unique_county_stcnty:\n",
    "        print('Processing:', county_stcnty)\n",
    "\n",
    "        # Filter the dataframe to include only the current county\n",
    "        county_svi_df = svi_od_filtered_state[svi_od_filtered_state['STCNTY'] == county_stcnty]\n",
    "\n",
    "        print('Number of rows:', len(county_svi_df))\n",
    "\n",
    "        # # Calculate the percentiles for each variable\n",
    "            # for variable in selected_variables_for_state:\n",
    "            #     percentiles_50[variable] = svi_od[variable].quantile(0.5)\n",
    "            #     percentiles_75[variable] = svi_od[variable].quantile(0.75)\n",
    "            #     percentiles_90[variable] = svi_od[variable].quantile(0.9)\n",
    "\n",
    "        # need to change here later\n",
    "\n",
    "        for variable_name in selected_variables_without_y:\n",
    "            \n",
    "            print('Processing:', variable)\n",
    "\n",
    "            # Sorting based on the variable and selecting only the FIPS and the variable columns is important\n",
    "            # Also we need to keep  the dataframe sorted based on the variable\n",
    "\n",
    "\n",
    "            # Cahanged FIPS into STCNTY\n",
    "            df_one_variable = county_svi_df[['STCNTY',variable_name, 'geometry']]\n",
    "\n",
    "            # # Sorting the DataFrame based on the 'rate' column\n",
    "            df_one_variable = df_one_variable.sort_values(by=variable_name)\n",
    "            df_one_variable['sortedID'] = range(len(df_one_variable))\n",
    "\n",
    "            # Convert the DataFrame to a GeoDataFrame\n",
    "            df_one_variable = gpd.GeoDataFrame(df_one_variable, geometry='geometry')\n",
    "            df_one_variable.crs = \"EPSG:3395\"  # This is a commonly used projected CRS\n",
    "\n",
    "            # Heter thresho;d removed from original adj method - change it later\n",
    "            adjacencies_list,adjacent_counties_df,county_list = generate_adjacent_counties(df_one_variable,variable_name)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        break\n",
    "    break\n",
    "\n",
    "\n",
    "print('All states processed.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TDA",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
